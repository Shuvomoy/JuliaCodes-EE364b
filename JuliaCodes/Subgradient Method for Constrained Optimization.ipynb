{
 "metadata": {
  "language": "Julia",
  "name": "",
  "signature": "sha256:30c1b241d44d43904d601d0d9303ae5c905159d2f832792985f6cf5be6fc7d95"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We consider the implementation of alternate subgradient method which solves the following optimization problem:\n",
      "\\begin{align}\n",
      "&\\textrm{minimize} \\quad f_0(x) \\\\\n",
      "&\\textrm{subject to} \\quad \\forall i \\in \\{1,\\ldots,m\\} \\quad f_i(x)\\leq0,\n",
      "\\end{align}\n",
      "where $f_i:\\mathbb{R}^n \\rightarrow \\mathbb{R}$ are convex. The update rule is the same as seen before:\n",
      "\\begin{align}\n",
      "x^{(k+1)}=x^{(k)}-\\alpha_{k} g^{(k)},\n",
      "\\end{align}\n",
      "however, now $g^{(k)}$ will depend on the feasibility of the current point $x^{k}$. Suppose, $h(x)=\\textrm{max}_{i \\in \\{1,\\ldots,m\\}}{f_i(x)}$. Then,\n",
      "\\begin{align}\n",
      "g^{(k)}=\\begin{cases}\n",
      " \\partial f_0(x^{(k)}), \\; &\\textrm{if} \\; h(x^{(k)})\\leq0, \\; \\textrm{i.e.,} \\; x^{(k)} \\; \\textrm{feasible}\\\\\n",
      "\\partial h(x^{(k)}) \\; &\\textrm{else}.\n",
      "\\end{cases}\n",
      "\\end{align}\n",
      "\n",
      "The step lengths are chosen as\n",
      "\\begin{align}\n",
      "\\alpha_k=\\begin{cases}\n",
      " (f_0(x^{(k)})-f^*)/\\|g^{(k)}\\|_2^2, \\; &\\textrm{if} \\; x^{(k)} \\; \\textrm{feasible} \\\\\n",
      " (f_i(x^{(k)})+\\epsilon)/\\|g^{(k)}\\|_2^2,  \\; &\\textrm{else}.\n",
      "\\end{cases}\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will apply the alternate subgradient method to a general form linear optimization problem.\n",
      "\\begin{align}\n",
      "&\\textrm{minimize} \\quad c^T x \\\\\n",
      "&\\textrm{subject to} \\quad \\forall i \\in \\{1,\\ldots,m\\} \\quad a_i^T x \\leq b_i,\n",
      "\\end{align}\n",
      "We generate the data in a manner that the problem has a finite optimum (otherwise we cannot test if the subgradient method is working!), i.e., the feasible set is nonempty and there is no extreme ray $d$ such that $c^T d < 0$. \n",
      "\n",
      "To ensure a nonempty feasible set we have a nonnegative $b=(b_1,\\ldots,b_m)$, so that $x=0$ is a feasible point. \n",
      "\n",
      "To prevent having a extreme ray leading to a cost unbounded below, we take $c=-A^T p$, where $p\\succeq 0$ is a randomly generated vector. For any extreme ray $d$ in the polyhedron there will exist a nonpositive vector $q$ such that $A d =-q$ (in fact any ray will satisfy this). Then no matter what $d$ we pick, $c^T d=(-A^T p)^T(A d)=-p^T (A d) = (-p)^T (-q) =p^T q \\geq 0$, so the optimal cost is finite."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n=20\n",
      "\n",
      "m=100\n",
      "\n",
      "A=randn(m,n)\n",
      "\n",
      "b=abs(randn(m,1)) \n",
      "\n",
      "c=-A'*abs(randn(m,1)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "20x1 Array{Float64,2}:\n",
        "  11.8554 \n",
        "   9.11255\n",
        "   1.38845\n",
        "  -6.88313\n",
        "  11.2945 \n",
        "  -4.11999\n",
        "   2.20051\n",
        "   2.25793\n",
        " -13.8604 \n",
        "  13.7328 \n",
        "  -8.20609\n",
        "  -3.23834\n",
        "  -8.92258\n",
        " -10.7669 \n",
        "  12.0445 \n",
        "  -6.17908\n",
        "  -4.02083\n",
        "   9.10532\n",
        "  -5.90859\n",
        "   2.9657 "
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we solve the problem using `Convex`. We will use the result to choose the step size."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using Convex\n",
      "\n",
      "using SCS\n",
      "\n",
      "xMin=Variable(n)\n",
      "\n",
      "problem=minimize(    c'*xMin,\n",
      "        #subject to\n",
      "                    A*xMin<=b)\n",
      "\n",
      "solve!(problem,SCSSolver())\n",
      "\n",
      "print(\n",
      "\"The status of the solution is \", problem.status,\n",
      "\"\\nwith optimal objective value, f(x*)=\", problem.optval,\n",
      ")\n",
      "xMinValue=xMin.value\n",
      "fMinValue=problem.optval"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The status of the solution is "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimal\n",
        "with optimal objective value, f(x*)=-6.979636309506132"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "-6.979636309506132"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we write a function to implement the alternate subgradient method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Function that will implement projected subgradient method\n",
      "# ---------------------------------------------------------\n",
      "function alternate_subgradient_ineq_LP(\n",
      "    A::Array{Float64,2},\n",
      "    b::Array{Float64,2},\n",
      "    c::Array{Float64,2},\n",
      "    x1::Array{Float64,2},\n",
      "    maxIter::Int64\n",
      "    )\n",
      "fSet=Float64[] # We are creating an empty array where we will store the objective values as we progress\n",
      "push!(fSet,Inf) # Intial value of f is infinity\n",
      "\n",
      "fBest=Float64[] # It is an array where the last element will give f_best^{(k)} so far\n",
      "push!(fBest, Inf) # Intial best value of f is infinity\n",
      "\n",
      "k=1\n",
      "x=x1\n",
      "  \n",
      "while(k < maxIter)\n",
      "    # Print the current iteration\n",
      "\n",
      "# Checking the feasibility of the current iterate\n",
      "constraintVector=A*x-b\n",
      "h=maximum(constraintVector)\n",
      "ind=indmax(constraintVector)\n",
      "\n",
      "# Determining the subgradient, updating fSet and fBest, and determining the step size depending on the feasibility of the current iterate\n",
      "if(h>0)# infeasible\n",
      "  g=A[ind,:]'\n",
      "  \u03b1=(h+\u03f5)/(norm(g)^2)\n",
      "  push!(fSet,Inf)\n",
      "  push!(fBest,fBest[end])# Best f value will not change \n",
      "else #feasible\n",
      "  g=c\n",
      "  fKval=(c'*x)[1,1]\n",
      "  \u03b1=(fKval-fMinValue)/(norm(g)^2)\n",
      "  push!(fSet,fKval)\n",
      "  push!(fBest, min(fBest[end],fKval))\n",
      "end\n",
      " \n",
      "# updating subgradient\n",
      "x=x-\u03b1*g\n",
      "if (mod(k,100)==0)\n",
      "  println(\"At iteration number=\",k)\n",
      "  println(\"Current best value of f=\", fBest[end])\n",
      "end    \n",
      "k=k+1\n",
      "end # while\n",
      "return x, fSet, fBest\n",
      "end # function\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "alternate_subgradient_ineq_LP (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x1=zeros(n,1)\n",
      "\u03f5=1e-3\n",
      "maxIter=3000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "3000"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's run the function for the current data with $0$ as the starting feasible point."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x1=zeros(n,1)\n",
      "\u03f5=1e-3\n",
      "maxIter=3000\n",
      "(xTest,fTest,fBestTest)=alternate_subgradient_ineq_LP(A,b,c,x1,maxIter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "At iteration number="
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100\n",
        "Current best value of f=-5.450083109919154\n",
        "At iteration number=200\n",
        "Current best value of f=-5.614308614289082\n",
        "At iteration number=300\n",
        "Current best value of f=-5.703239067884826\n",
        "At iteration number=400\n",
        "Current best value of f=-5.835287720349045\n",
        "At iteration number=500\n",
        "Current best value of f=-5.952974908194274\n",
        "At iteration number=600\n",
        "Current best value of f=-6.049427689913004\n",
        "At iteration number=700\n",
        "Current best value of f=-6.165332353500256\n",
        "At iteration number=800\n",
        "Current best value of f=-6.206326125333209\n",
        "At iteration number=900\n",
        "Current best value of f=-6.278491992131651\n",
        "At iteration number=1000\n",
        "Current best value of f=-6.34116761866385\n",
        "At iteration number=1100\n",
        "Current best value of f=-6.3847370103934775\n",
        "At iteration number=1200\n",
        "Current best value of f=-6.412511055866619\n",
        "At iteration number=1300\n",
        "Current best value of f=-6.476672823664339\n",
        "At iteration number=1400\n",
        "Current best value of f=-6.497059206200993\n",
        "At iteration number=1500\n",
        "Current best value of f=-6.542138674047012\n",
        "At iteration number=1600\n",
        "Current best value of f=-6.571916578209762\n",
        "At iteration number=1700\n",
        "Current best value of f=-6.606102757905508\n",
        "At iteration number=1800\n",
        "Current best value of f=-6.629244527374161\n",
        "At iteration number=1900\n",
        "Current best value of f=-6.659937266652632\n",
        "At iteration number=2000\n",
        "Current best value of f=-6.690418386124115\n",
        "At iteration number=2100\n",
        "Current best value of f=-6.707284537972992\n",
        "At iteration number=2200\n",
        "Current best value of f=-6.721549214279016\n",
        "At iteration number=2300\n",
        "Current best value of f=-6.7555641613999775\n",
        "At iteration number=2400\n",
        "Current best value of f=-6.765133172466109\n",
        "At iteration number=2500\n",
        "Current best value of f=-6.774133505775753\n",
        "At iteration number=2600\n",
        "Current best value of f=-6.7893375636484325\n",
        "At iteration number=2700\n",
        "Current best value of f=-6.789623852357104\n",
        "At iteration number=2800\n",
        "Current best value of f=-6.791220170210107\n",
        "At iteration number=2900\n",
        "Current best value of f=-6.803097624150005\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "(\n",
        "20x1 Array{Float64,2}:\n",
        " -0.181265  \n",
        " -0.213302  \n",
        " -0.105308  \n",
        " -0.0466105 \n",
        " -0.031399  \n",
        " -0.0799105 \n",
        " -0.0832833 \n",
        " -0.0865174 \n",
        "  0.0797812 \n",
        " -0.0908816 \n",
        " -0.0247272 \n",
        " -0.0996257 \n",
        "  0.0837221 \n",
        " -0.0191309 \n",
        "  0.00654876\n",
        " -0.0240963 \n",
        " -0.00674767\n",
        " -0.0784566 \n",
        " -0.0690574 \n",
        " -0.0287183 ,\n",
        "\n",
        "[Inf,0.0,Inf,Inf,Inf,Inf,Inf,Inf,Inf,Inf  \u2026  Inf,Inf,Inf,-6.78915,Inf,Inf,Inf,Inf,Inf,Inf],[Inf,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0  \u2026  -6.8031,-6.8031,-6.8031,-6.8031,-6.8031,-6.8031,-6.8031,-6.8031,-6.8031,-6.8031])"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally we plot $f_{\\textrm{best}}^{(k)}$ versus $k$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plotting time\n",
      "#-------------\n",
      "using Winston\n",
      "iters=[1:maxIter]\n",
      "figAltSub = FramedPlot(\n",
      "title=\"The value of f_{best}^{(k)} - f^{*} vs. iteration number\",\n",
      "         xlabel=\"k\",\n",
      "         ylabel=\"f_{best}^{(k)} - f^{*}\",\n",
      "yrange=(1e-2,1e0),\n",
      "ylog=true\n",
      ")\n",
      "xAxis=iters\n",
      "curve1=fBestTest-fMinValue\n",
      "bl=Curve(xAxis, curve1, color=\"blue\")\n",
      "setattr(bl, label=\"0.1/k\")\n",
      "le=Legend(.1,.1,{bl})\n",
      "add(figAltSub,bl)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "png": "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",
       "prompt_number": 19,
       "text": [
        "FramedPlot(...)"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}